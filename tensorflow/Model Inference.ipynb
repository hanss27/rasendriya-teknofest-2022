{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"},"colab":{"name":"Model Inference.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"om4F-C8tyHN7"},"source":["import numpy as np\n","import os\n","import sys\n","import tensorflow as tf\n","import pathlib\n","import time\n","\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","from IPython.display import display"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KdD7PKquyHOQ"},"source":["from object_detection.utils import ops as utils_ops\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R6n2pDo7yHOS"},"source":["PATH_TO_LABELS = \"REPLACE_WITH_LABELS_DIRECTORY\" # Example: ./datasets/pascal_label_map.pbtxt\n","category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS,\n","                                                                    use_display_name=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"id":"Kh5Gcv6ByHOS"},"source":["print('Loading model...', end='')\n","start_time = time.time()\n","\n","PATH_TO_SAVED_MODEL = \"REPLACE_WITH_MODEL_DIRECTORY\" # Example: ./models/orange-ssd-mobilenet-v2-320x320/saved_model\n","detection_model = tf.saved_model.load(PATH_TO_SAVED_MODEL)\n","\n","end_time = time.time()\n","elapsed_time = end_time - start_time\n","print('Done! Took {} seconds'.format(elapsed_time))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8HAIaiBByHOU","executionInfo":{"status":"ok","timestamp":1612874470572,"user_tz":-420,"elapsed":1138,"user":{"displayName":"Muhammad Rizky Millennianno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXj3Ba5cpG6yF8YJghYLjxCF8TUME-CADWnOdCkw=s64","userId":"11043010082713873441"}}},"source":["def run_inference_for_single_image(model, image):\n","    image = np.asarray(image)\n","    # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n","    input_tensor = tf.convert_to_tensor(image)\n","    # The model expects a batch of images, so add an axis with `tf.newaxis`.\n","    input_tensor = input_tensor[tf.newaxis,...]\n","    \n","    # Run inference\n","    model_fn = model.signatures['serving_default']\n","    output_dict = model_fn(input_tensor)\n","    \n","    # All outputs are batches tensors.\n","    # Convert to numpy arrays, and take index [0] to remove the batch dimension.\n","    # We're only interested in the first num_detections.\n","    num_detections = int(output_dict.pop('num_detections'))\n","    output_dict = {key:value[0, :num_detections].numpy() \n","                   for key,value in output_dict.items()}\n","    output_dict['num_detections'] = num_detections\n","    \n","    # detection_classes should be ints.\n","    output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n","    \n","    # Handle models with masks:\n","    if 'detection_masks' in output_dict:\n","        # Reframe the the bbox mask to the image size.\n","        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","            output_dict['detection_masks'], output_dict['detection_boxes'],\n","            image.shape[0], image.shape[1])\n","        detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5, \n","                                           tf.uint8)\n","        output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n","    return output_dict"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E5gXXhdOyHOV"},"source":["# Image Inference"]},{"cell_type":"code","metadata":{"id":"PXRFwKk-yHOV","executionInfo":{"status":"ok","timestamp":1612874468398,"user_tz":-420,"elapsed":801,"user":{"displayName":"Muhammad Rizky Millennianno","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiXj3Ba5cpG6yF8YJghYLjxCF8TUME-CADWnOdCkw=s64","userId":"11043010082713873441"}}},"source":["def show_inference(model, image_path):\n","    # the array based representation of the image will be used later in order to prepare the\n","    # result image with boxes and labels on it.\n","    image_np = np.array(Image.open(image_path))\n","    # Actual detection.\n","    output_dict = run_inference_for_single_image(model, image_np)\n","    # Visualization of the results of a detection.\n","    vis_util.visualize_boxes_and_labels_on_image_array(\n","        image_np,\n","        output_dict['detection_boxes'],\n","        output_dict['detection_classes'],\n","        output_dict['detection_scores'],\n","        category_index,\n","        instance_masks=output_dict.get('detection_masks_reframed', None),\n","        use_normalized_coordinates=True,\n","        line_thickness=8)\n","\n","    display(Image.fromarray(image_np))"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"KvdiBDEOyHOW"},"source":["PATH_TO_TEST_IMAGES_DIR = pathlib.Path('REPLACE_WITH_IMAGES_DIRECTORY') # Example: ./datasets/images\n","TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n","for image_path in TEST_IMAGE_PATHS:\n","    show_inference(detection_model, image_path)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"llywTClTyHOX"},"source":["# Video Stream Inference"]},{"cell_type":"code","metadata":{"scrolled":false,"id":"fXIFoQRfyHOX"},"source":["import cv2\n","\n","TEST_VIDEO_PATHS = r\"REPLACE_WITH_VIDEO_DIRECTORY\" # Example: \"C:/Users/Video\" \n","\n","cap = cv2.VideoCapture(rTEST_VIDEO_PATHS) # or cap = cv2.VideoCapture(\"<video-path>\")\n","\n","def run_inference(model, cap):\n","    while cap.isOpened():\n","        ret, image_np = cap.read()\n","        # Actual detection.\n","        output_dict = run_inference_for_single_image(model, image_np)\n","        # Visualization of the results of a detection.\n","        vis_util.visualize_boxes_and_labels_on_image_array(\n","            image_np,\n","            output_dict['detection_boxes'],\n","            output_dict['detection_classes'],\n","            output_dict['detection_scores'],\n","            category_index,\n","            instance_masks=output_dict.get('detection_masks_reframed', None),\n","            use_normalized_coordinates=True,\n","            line_thickness=5)\n","        cv2.imshow('object_detection', cv2.resize(image_np, (320, 240)))\n","        \n","        if cv2.waitKey(25) & 0xFF == ord('q'):\n","            cap.release()\n","            out.release()\n","            cv2.destroyAllWindows()\n","            break\n","\n","run_inference(detection_model, cap)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hlGsopwdyHOY"},"source":[""],"execution_count":null,"outputs":[]}]}